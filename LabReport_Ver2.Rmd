---
title: "Lab Report Ver2"
author: "Aaron Willcox"
date: "03/08/2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

## Why R? Whats Wrong with SPSS? :

The following are the core notes I took as I went through, cleaned and analysed data from a research capstone project on Subjective Wellbeing. This was my first attempt at both learning R, Github and the idea of reproducible research. I have outlined the process below as I stepped through the analysis. There are many errors and there are certainly many ways to streamline this process. However, I think it is important to view what and how I approached this, as to reflect on what and where i could improve. This could also help others to see and learn who want to attempt this process (Highly suggest undergraduates have a go!). In future posts I aim to share how I setup R Studio, Github and markdown so that if anyone is interested then they can replicate this process. You can also see all my relevant code and documents over [here at Github](https://github.com/psychtek/hps327). 

Once this process was done a script was created with the final dataframe with the added columns that were mutated throughout. This was then the source script used in an APA template in R Studio. You can [check this script out here](https://github.com/psychtek/hps327/blob/master/analysis.R) and the final PDF report printed here. Given the time constraints I used the apaTables packge to print the tables needed to a seperate word document and edited these into the final report. The one presented here is the version that is printed directly from the template with inline code using the apa_print function in papaja. 

Having the source script is handy as it allows you to pull the results into the part of the text and update these as needed depending on your report. Handy! 
You can see the final [lab report script here](https://github.com/psychtek/hps327/blob/master/my_report.Rmd)  where the _source("analysis.R")_ is called before then writing up the results as interpreted below. You can read my finals thoughts on the data at the end of the script below. 

## What did I learn? 
1. Learning to undertake R during the term was exciting, engaging and super time consuming. I would only encourge this if you have the time. Doing the analyis this way also gave me a broader understanding of how regression works. Stack exchange and Google are your friends, more often coding problems that you'll come across, someone has experienced them before. 

2. Learning to visualise the how a data frame works and the different types of data structures helps understand why some functions may not work. Some objects may need to be changed to numeric or a matrix for the specific function to run. 

3. Use Github and commit often. It will save headaches later on when you need to look back over your code when something goes wrong. Pretty much everything I did is now open to the world to view on github. This is also the core idea of reproducibility, if this was in real collaborative setting, the process can be replicated and adjusted as needed, making for a much stronger scientific  community. 

## Whats wrong with SPSS? 

Everything. R is Free. 

You can view the project at [OSF](https://osf.io/z2brh/) or at [Github](https://github.com/psychtek/hps327). 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Included Library, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Included librarys for functions
library(psych)
library(haven)
library(dplyr)
library(lmSupport)
library(papaja)
library(broom)
library(car)
library(olsrr)
library(xtable)
library(apaTables)
library(MBESS)
library(corrplot)
```

**DV:** Personal Wellbeing Index (pwi)  
**IVs:** Affect(affect HPMood), Cogniton(cognition, MDT), Gender(gender), Personality(personality)
***

```{r Import and Check Data, include=FALSE}
well_being_df <- read_sav("data/Wellbeing_2018.sav")
nrows <- nrow(well_being_df)
ncomplete <- sum(complete.cases(well_being_df))
ncomplete/nrows

# Check for missing or na data
which(is.na(well_being_df))
```

## Compute Variables

All items for the Personal Wellbeing Index (PWI) are measured along a scale ranging from 0 (No satisfaction at all) to 10 (Completely satisfied)
*Total scores on the PWI are obtained by obtaining the average score across the 7 items and then multiplying by 10 to stretch the scale to 0 to 100. 
*As per the PWI manual (http://www.acqol.com.au/uploads/pwi-a/pwi-a-english.pdf ), anyone who scores 0 or 100 is considered unreliable and their data are excluded from analyses involving the PWI (including descriptive statistics such as mean score on the PWI). 
Then mutate this to a new column called "PW_Index"
```{r PWI Score}
well_being_df <- well_being_df %>% 
  mutate(PW_Index = (
    PWI1 + 
      PWI2 + 
      PWI3 + 
      PWI4 + 
      PWI5 + 
      PWI6 + 
      PWI7)/7*10)

# Check for scores of zero or 100
PWI_score_check <- filter(well_being_df, well_being_df$PW_Index == 100)

# score of 100 identified at row 1
well_being_df[1,]

# remove the row
well_being_df <- well_being_df[-1,]



```

## Personality 

Notes:
Items are scored on a scale with options 1 = _strongly disagree_, 2 = _disagree_, 3 = _neither agree nor disagree_, 4 = _agree_, and 5 = _strongly agree_.

+ Items 1-10 assess __neuroticism__. Items 6-10 need to be reverse coded so that high scores across all ten items reflect high levels of neuroticism.

+ Items 11-20 assess __extraversion__. Items 16-20 need to be reverse coded so that high scores across all ten items reflect high levels of extraversion.

+ Items 21-30 assess __openness to experience__. Items 26-30 need to be reverse coded so that high scores across all ten items reflect high levels of openness.

+ Items 31-40 assess __agreeableness__. Items 36-40 need to be reverse coded so that high scores across all ten items reflect high levels of agreeableness.
 
+ Items 41-50 assess __conscientiousness__. Items 46-50 need to be reverse coded so that high scores across all ten items reflect high levels of conscientiousness.
 
Create the total scores for the subscales by averaging items. These are summed and mutated to a new column for each peronality trait.

```{r Personality}

#Reverse score items 
# M. Ling invert function
invertItem <- function(x, min, max) {
  if(!is.numeric(x) | !is.numeric(min) | !is.numeric(max)) stop("Inputs are not numeric")
  ifelse(max<min, stop("Maximum value is less than minimum value"), "")
  ifelse(x>max | x < min, stop("Value is out of expected range"), "")
  
  reb <- (min-1)
  (max - reb + 1) - (x - reb) + reb
}



# Personality Traits
well_being_df <- well_being_df %>% 
  mutate(Neuroticism = ( # Neuroticism
    Personality1 + 
      Personality2 +
      Personality3 +
      Personality4 +
      Personality5 +
      invertItem(Personality6, 1, 5) +
      invertItem(Personality7, 1, 5) +
      invertItem(Personality8, 1, 5) +
      invertItem(Personality9, 1, 5) +
      invertItem(Personality10, 1, 5)), 
    Extraversion = ( # extraversion
      Personality11 + 
        Personality12 +
        Personality13 +
        Personality14 +
        Personality15 +
        invertItem(Personality16, 1, 5) +
        invertItem(Personality17, 1, 5) +
        invertItem(Personality18, 1, 5) +
        invertItem(Personality19, 1, 5) +
        invertItem(Personality20, 1, 5)),
    Openness = ( # openness
      Personality21 + 
        Personality22 +
        Personality23 +
        Personality24 +
        Personality25 +
        invertItem(Personality26,1,5) +
        invertItem(Personality27,1,5) +
        invertItem(Personality28,1,5) +
        invertItem(Personality29,1,5) +
        invertItem(Personality30,1,5)),
    Agreeableness = ( # Agreeableness
      Personality31 + 
        Personality32 +
        Personality33 +
        Personality34 +
        Personality35 +
        invertItem(Personality36, 1, 5) +
        invertItem(Personality37, 1, 5) +
        invertItem(Personality38, 1, 5) +
        invertItem(Personality39, 1, 5) +
        invertItem(Personality40, 1, 5)),
    Conscientiousness  = (  # conscientiousness
      Personality41 + 
        Personality42 +
        Personality43 +
        Personality44 +
        Personality45 +
        invertItem(Personality46, 1, 5) +
        invertItem(Personality47, 1, 5) +
        invertItem(Personality48, 1, 5) +
        invertItem(Personality49, 1, 5) +
        invertItem(Personality50, 1, 5)))
     
```

## Homeostatically Protected Mood (Core Affect)

Please indicate how each of the following describes your feelings when you think about your life in general.

1. Happy do you generally feel?

2. Content do you generally feel?

3. Alert do you generally feel?

Notes:
Each item is scored on an end-defined rating scale with 0 = _not at all_, and 10 = _extremely_.
Items are averaged to provide a single value reflecting homeostatically protected mood ( __HPMood__ ).


```{r HPMood}
well_being_df <- well_being_df %>% 
  mutate(HPMood = 
           (Affect1 + # Happy
              Affect2 + # Content
              Affect3)/3) # Alert

```


## Multiple Discrepancies Theory (MDT) - Cognition 

Items are averaged to indicate gap between desired and actual life circumstances, such that scores closer to 0 indicate actual circumstances less than desired, scores around 5 reflect life circumstances on par with desired level, and scores closer to 10 indicate actual circumstances are much better than desired.
Mutate to a new column labelled "MDT" and averaged.  

1. self_wants 
2. self_other 
3. self_deserves
4. self_needs 
5. self_progress
6. self_future
7. self_past  


```{r MDT}
# This will create a new variable with the overal MDT cognition mean score
well_being_df <- well_being_df %>%  
  mutate(MDT =  (
    Cognition1 +
      Cognition2 +
      Cognition3 +
      Cognition4 +
      Cognition5 +
      Cognition6 +
      Cognition7)/7
  )

```

## Visualise data

```{r Descriptives}

Descriptives_one <- describe(well_being_df[c(1,2,71:78)], fast = TRUE) #descriptives

Descriptives_one #print descriptive statistics

```


```{r PWI_Plots}

# DV Personal wellbeing index
boxplot(as.numeric(well_being_df$PW_Index)
        , horizontal = TRUE
     , main = "Personal Wellbeing Index"
     , outline = TRUE
     , outwez = TRUE) 
hist(well_being_df$PW_Index)
plot(well_being_df$PW_Index)
```

```{r IV_Plots}

 #HPMood - Affect
boxplot(as.numeric(well_being_df$HPMood)
        , main = "HPMood"
        , horizontal = TRUE
        , outline = TRUE)

plot(well_being_df$HPMood)

#MDT - Cognition
boxplot(as.numeric(well_being_df$MDT) 
        , main = "MDT"
        , horizontal = TRUE)

plot(well_being_df$MDT)


# Create an object with the required columns
boxplot_big5 <- cbind(well_being_df$Neuroticism,
                      well_being_df$Extraversion, 
                      well_being_df$Openness, 
                      well_being_df$Agreeableness, 
                      well_being_df$Conscientiousness) 

#in order to name the boxplot more clearly, create an object with the names
boxplot_names_big5 <- c("N", "E", "O", "A", "C")

# Create a boxplot and use the object boxplot_names_big5 to label each one
boxplot(boxplot_big5, main = "Big 5 Means", names = boxplot_names_big5, horizontal = FALSE) 

```


# Correlations

```{r CorrelationTable, results="asis" }

corr_Matrix <- cor(well_being_df[c(71:78)]) #subset relevant columns and use cor() to create a matrix
corrplot(corr_Matrix, method = "number")

```


## Hierarchical Regression Model 1

Controlling for affect based on previous research that affect is the larger component to subjective wellbeing at step 1. MDT was entered at stage two after controlling for affect and the five personality traits entered as a group at stage three.
```{r Regression_Part_1}

model1 <- lm(PW_Index ~ 
             HPMood
             , data = well_being_df)

model2 <- lm(PW_Index ~ 
              HPMood
             + MDT 
             , data = well_being_df)

model3 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)


model_comparison_1 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)

#apa.reg.table(model1, model2, model3) #using apaTables package to present the model an a table. 

# Run an ANOVA to check for effect. 
ANOVA_Models <- anova(model1, model2, model3)
ANOVA_Models # print results to screen

```

## Model analysis 
Results look good however, its good to visualise the model and check for any leveraging. linear regression needs the relationship between the independent and dependent variables to be linear.  It is also important to check for outliers since linear regression is sensitive to outlier effects.

The results are then converted to APA format using the papaja package and then knitted using a APA template. Printed here for analyis: 
```{r}

summary(model1)
summary(model2)
summary(model3)
anova(model1, model2, model3)

```


## Normality and Residuals
```{r}
modelAssumptions(model3) #use the lmsupport library as it provides diagnostic graphs and tests to evaluate linear model assumptions of normality.
model_assump_one <- modelAssumptions(model3)
```

shapiro-wilk test: compares scores in sample to to norm dist. If the test test is non-sig p>.05 tells us the the dist of sample is not sig different from normal
If test is sig _p_<.05 then the distribution in question is significant different from normal. 

## Warning: large sample sizes may get different results. Always plot!

```{r Residuals}

my_residuals <- residuals(model3)

shapiro.test( x = my_residuals )  # which finds no indication that normality is violated 

```

## Cooks Distance 
Cook's distance is a measure of the overall influence of a case on a model. Values greater than one may be cause of concern. 

```{r}

residualPlots(model3)

model3_cooksd <- cooks.distance(model3)

plot(model3_cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance") %>%  # plot cook's distance
  abline(h = 4*mean(model3_cooksd, na.rm=T), col="red") %>%  # add cutoff line - scores 4 times greater than mean
  text(x=1:length(model3_cooksd)+1
       , y=model3_cooksd
       , labels=ifelse(model3_cooksd>4*mean(model3_cooksd, na.rm=T)
                       ,names(model3_cooksd),"")
       , col="red")  # add labels

# find out which rows are influencial
influential <- as.numeric(names(model3_cooksd)[(model3_cooksd > 4*mean(model3_cooksd, na.rm=T))])  # influential row numbers
# head(well_being_df[influential, ])  # influential observations.

outlierTest(model3) #get the most extreme outlier and return row number

# Print which rows are most influencial
influential

# Remove rows
#well_being_df <- well_being_df[-c(2, 19, 21, 84), ]
well_being_df <- well_being_df[-c(2, 21, 27, 30, 78, 84, 86, 88, 101, 104), ]
qqPlot(as.numeric(well_being_df$PW_Index))
modelAssumptions(model3)
```


## Compare models before and after adjustments 
```{r}
model_comparison_2 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)
model_assump_two <- modelAssumptions(model3)

summary(model_comparison_1)
summary(model_comparison_2)
model_assump_one 
model_assump_two

```


## Reliability

Check alpha levels (omega) for intercorrelations on each domain. Using the MBES package

# Personal wellbeing index

The combined survey mean scores from 28 surveys of the Australian population have produced a maximum variation of 3.2 percentage points in subjective wellbeing (see Australian Unity Wellbeing Index Report 28.0). Cronbach alpha lies between .70 and .85 in Australia and overseas. Inter-domain correlations are often moderate at round .30 to .55 and item-total correlations are at least .50. The index has also demonstrated good test-retest reliability across 1-2 week interval with an intra-class correlation coefficient of 0.84 (Lau and Cummins, 2005).    


```{r Reliability}

well_being_df <- well_being_df %>% #create an object with personality constructs and reversed scored items
  mutate(Personality6_R =  invertItem(Personality6, 1, 5),
         Personality7_R =  invertItem(Personality7, 1, 5),
         Personality8_R =  invertItem(Personality8, 1, 5),
         Personality9_R =  invertItem(Personality9, 1, 5),
         Personality10_R = invertItem(Personality10, 1, 5),
         Personality16_R = invertItem(Personality16, 1, 5),
         Personality17_R = invertItem(Personality17, 1, 5),
         Personality18_R = invertItem(Personality18, 1, 5),
         Personality19_R = invertItem(Personality19, 1, 5),
         Personality20_R = invertItem(Personality20, 1, 5),
         Personality26_R = invertItem(Personality26, 1,5),
         Personality27_R = invertItem(Personality27, 1,5),
         Personality28_R = invertItem(Personality28, 1,5),
         Personality29_R = invertItem(Personality29, 1,5),
         Personality30_R = invertItem(Personality30, 1,5),
         Personality36_R = invertItem(Personality36, 1, 5),
         Personality37_R = invertItem(Personality37, 1, 5),
         Personality38_R = invertItem(Personality38, 1, 5),
         Personality39_R = invertItem(Personality39, 1, 5),
         Personality40_R = invertItem(Personality40, 1, 5),
         Personality46_R = invertItem(Personality46, 1, 5),
         Personality47_R = invertItem(Personality47, 1, 5),
         Personality48_R = invertItem(Personality48, 1, 5),
         Personality49_R = invertItem(Personality49, 1, 5),
         Personality50_R = invertItem(Personality50, 1, 5))

neo_reliability <- select(well_being_df
         , Personality1
         , Personality2
         , Personality3
         , Personality4
         , Personality5
         , Personality6_R
         , Personality7_R
         , Personality8_R
         , Personality9_R
         , Personality10_R)

ext_reliability <- select(well_being_df
         , Personality11
         , Personality12
         , Personality13
         , Personality14
         , Personality15
         , Personality16_R
         , Personality17_R
         , Personality18_R
         , Personality19_R
         , Personality20_R)


opn_reliability <- select(well_being_df
         , Personality21
         , Personality22
         , Personality23
         , Personality24
         , Personality25
         , Personality26_R
         , Personality27_R
         , Personality28_R
         , Personality29_R
         , Personality30_R)

agre_reliability <- select(well_being_df
         , Personality31
         , Personality32
         , Personality33
         , Personality34
         , Personality35
         , Personality36_R
         , Personality37_R
         , Personality38_R
         , Personality39_R
         , Personality40_R)

conc_reliability <- select(well_being_df
                     , Personality41
                     , Personality42
                     , Personality43
                     , Personality44
                     , Personality45
                     , Personality46_R
                     , Personality47_R
                     , Personality48_R
                     , Personality49_R
                     , Personality50_R)
#run intercorrelation checks
#corPlot(neo_omega)
omega(neo_reliability)

#corPlot(ext_omega)
omega(ext_reliability)

#corPlot(opn_omega)
omega(opn_reliability)

#corPlot(agre_omega)
omega(agre_reliability)

#corPlot(conc_omega)
omega(conc_reliability)

HPmood_omega <- ci.reliability(select(well_being_df, Affect1, Affect2, Affect3))

MDT_omega <- ci.reliability(select(well_being_df
             , Cognition1
             , Cognition2
             , Cognition3
             , Cognition4
             , Cognition5
             , Cognition6
             , Cognition7))

pwi_omega <- ci.reliability(select(well_being_df
             , PWI1
             , PWI2
             , PWI3
             , PWI4
             , PWI5
             , PWI6
             , PWI7))



```


### Re run models

With outliers removed that were leveraging the model, re-run the model. 
```{r Final-model}


model1 <- lm(PW_Index ~ 
             HPMood
             , data = well_being_df)

model2 <- lm(PW_Index ~ 
              HPMood
             + MDT 
             , data = well_being_df)

model3 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)


apa.reg.table(model1, model2, model3)

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3)
```

```{r Cooks}
#Cooks distance check 
model_residuals_3 <- residuals(model3)
shapiro_model <- shapiro.test( x = model_residuals_3 )

model3_residuals_H1 <- cooks.distance(model3)

plot(model3_residuals_H1, pch="*", cex=2, main="Influential Obs by Cooks distance") %>%  # plot cook's distance
  abline(h = 4*mean(model3_residuals_H1, na.rm=T), col="red") %>% # add cutoff line - scores 4 times greater than mean
  text(x=1:length(model3_residuals_H1)+1
       , y=model3_residuals_H1
       , labels=ifelse(model3_residuals_H1>4*mean(model3_residuals_H1, na.rm=T)
                       ,names(model3_residuals_H1),"")
       , col="red")  # add labels

Bonferonni_model <- outlierTest(model3) #get the most extreme outlier and return row number

residualPlots(model3)
Bonferonni_model
```

### With outliers removed re-run the correlations and descriptives

```{r Descriptives2}

Descriptives2 <- describe(well_being_df[c(1,2,71:78)], fast = TRUE) #descriptives

Descriptives2 #print descriptive statistics

```


```{r CorrelationTable2, results="asis" }

corr_Matrix2 <- cor(well_being_df[c(71:78)]) #subset relevant columns and use cor() to create a matrix
corrplot(corr_Matrix2, method = "number")

```
 
## Print Final Model Results

```{r Papaja Table}
summary(model1)
summary(model2)
summary(model3)
```

```{r Partials}

model1_tolerance_vif <- ols_coll_diag(model1) #Tolerance and vif values

model2_tolerance_vif <- ols_coll_diag(model2)

model3_tolerance_vif <- ols_coll_diag(model3)

#model4_tolerance_vif <- ols_coll_diag(model4)

#model1_partials <- ols_correlations(model1) #part and partials

model2_partials <- ols_correlations(model2)

model3_partials <- ols_correlations(model3)

#model4_partials <- ols_correlations(model4)
```

```{r tolerance_partials}
#model1_tolerance_vif$vif_t
#model1_partials

model2_tolerance_vif$vif_t
model2_partials

model3_tolerance_vif$vif_t
model3_partials

#model4_tolerance_vif$vif_t
#model4_partials

```

## Some thoughts as I worked through the data:

The mean score of the sample was 68.80 with a standard deviation of 10.50 which was outside of the normal range indicated by previous research (studies shows the average for a sample should fall between 73.43 - 76.43 points Cummins, 2010). This can also be indicated by the change in model when MDT is introduced, the change was not significant. suggesting that affect is the prefered component when there is an indication of a shift in subjective wellbeing outside of the normal range. This could have good clinical applications as determining an individuals SWB and personality could highlight distress or challenging experiences. This is also evident in the _b_ weights as when cognition is entered in each step the affect component is reduced. The components of cognition and affect are competing for space in the model and under normal circumstances, a cognitive-affective model would be used. However, in light of the mean score of the sample, we have a purely affective model when there is evidence of challenging experiences of the sample. 

We can also see how removing the outliers in the model increased the R coefficeint and zero order correlations. The final model variance in model one accounted for 53% of the variance in SWB and then the adjusted model after removing outliers using Cook's methodology, increased to 68%. 

Its interesting to find that Neuroticism and PWI were strongly negative in the correlation. Which shouldnt be surprising as an increase in wellbeing should mean a decrease in feeling neurotic. The Extraversion was positve which contrasts with the directionality of neuroticism and SWB. HPMood (affect) was also strongly postive on PWI, indicating good fit for affect for use in SWB. This is important as persons setpoint might be lower if they are feeling depressed or neurotic and in contrast, an extraverted person will more likekly correlate higher with the PWI setpoint when they are feeling in a more positive disposition. 

With this in mind further exploratory analysis was conducted to test the affective component with neuroticism. We can see the b of affect is still the strongest unique contributor to SWB and that Neuroticism is significant with a smaller effect size however, the overall model variance is 66%.
```{r Explore}

model4_explore <- lm(PW_Index ~
                       HPMood
                     + Neuroticism, data = well_being_df)

summary(model4_explore)

```


