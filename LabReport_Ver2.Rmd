---
title: "Lab Report Ver2"
author: "Aaron Willcox"
date: "03/08/2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Included Library, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Included librarys for functions
library(psych)
library(haven)
library(dplyr)
library(lmSupport)
library(papaja)
library(broom)
library(car)
library(olsrr)
library(xtable)
library(apaTables)
library(MBESS)
```

**DV:** Personal Wellbeing Index (pwi)  
**IVs:** Affect(affect HPMood), Cogniton(cognition, MDT), Gender(gender), Personality(personality)
***

```{r Import and Check Data, include=FALSE}
well_being_df <- read_sav("data/Wellbeing_2018.sav")
nrows <- nrow(well_being_df)
ncomplete <- sum(complete.cases(well_being_df))
ncomplete/nrows

# Check for missing or na data
which(is.na(well_being_df))
```

### Compute Variables

All items for the Personal Wellbeing Index (PWI) are measured along a scale ranging from 0 (No satisfaction at all) to 10 (Completely satisfied)
*Total scores on the PWI are obtained by obtaining the average score across the 7 items and then multiplying by 10 to stretch the scale to 0 to 100. 
*As per the PWI manual (http://www.acqol.com.au/uploads/pwi-a/pwi-a-english.pdf ), anyone who scores 0 or 100 is considered unreliable and their data are excluded from analyses involving the PWI (including descriptive statistics such as mean score on the PWI). 
Then mutate this to a new column called "PW_Index"
```{r PWI Score}
well_being_df <- well_being_df %>% 
  mutate(PW_Index = (
    PWI1 + 
      PWI2 + 
      PWI3 + 
      PWI4 + 
      PWI5 + 
      PWI6 + 
      PWI7)/7*10)

# Check for scores of zero or 100
PWI_score_check <- filter(well_being_df, well_being_df$PW_Index == 100)

# score of 100 identified at row 1
well_being_df[1,]

# remove the row
well_being_df <- well_being_df[-1,]



```

## Personality 

Notes:
Items are scored on a scale with options 1 = strongly disagree, 2 = disagree, 3 = neither agree nor disagree, 4 = agree, and 5 = strongly agree.
Items 1-10 assess neuroticism. Items 6-10 need to be reverse coded so that high scores across all ten items reflect high levels of neuroticism.

Items 11-20 assess extraversion. Items 16-20 need to be reverse coded so that high scores across all ten items reflect high levels of extraversion.

Items 21-30 assess openness to experience. Items 26-30 need to be reverse coded so that high scores across all ten items reflect high levels of openness.

Items 31-40 assess agreeableness. Items 36-40 need to be reverse coded so that high scores across all ten items reflect high levels of agreeableness.

Items 41-50 assess conscientiousness. Items 46-50 need to be reverse coded so that high scores across all ten items reflect high levels of conscientiousness.

Create the total scores for the subscales by averaging items.
 
These are summed and mutated to a new column for each peronality trait.

```{r Personality}

#Reverse score items 
# M. Ling invert function
invertItem <- function(x, min, max) {
  if(!is.numeric(x) | !is.numeric(min) | !is.numeric(max)) stop("Inputs are not numeric")
  ifelse(max<min, stop("Maximum value is less than minimum value"), "")
  ifelse(x>max | x < min, stop("Value is out of expected range"), "")
  
  reb <- (min-1)
  (max - reb + 1) - (x - reb) + reb
}



# Personality Traits
well_being_df <- well_being_df %>% 
  mutate(Neuroticism = ( # Neuroticism
    Personality1 + 
      Personality2 +
      Personality3 +
      Personality4 +
      Personality5 +
      invertItem(Personality6, 1, 5) +
      invertItem(Personality7, 1, 5) +
      invertItem(Personality8, 1, 5) +
      invertItem(Personality9, 1, 5) +
      invertItem(Personality10, 1, 5)), 
    Extraversion = ( # extraversion
      Personality11 + 
        Personality12 +
        Personality13 +
        Personality14 +
        Personality15 +
        invertItem(Personality16, 1, 5) +
        invertItem(Personality17, 1, 5) +
        invertItem(Personality18, 1, 5) +
        invertItem(Personality19, 1, 5) +
        invertItem(Personality20, 1, 5)),
    Openness = ( # openness
      Personality21 + 
        Personality22 +
        Personality23 +
        Personality24 +
        Personality25 +
        invertItem(Personality26,1,5) +
        invertItem(Personality27,1,5) +
        invertItem(Personality28,1,5) +
        invertItem(Personality29,1,5) +
        invertItem(Personality30,1,5)),
    Agreeableness = ( # Agreeableness
      Personality31 + 
        Personality32 +
        Personality33 +
        Personality34 +
        Personality35 +
        invertItem(Personality36, 1, 5) +
        invertItem(Personality37, 1, 5) +
        invertItem(Personality38, 1, 5) +
        invertItem(Personality39, 1, 5) +
        invertItem(Personality40, 1, 5)),
    Conscientiousness  = (  # conscientiousness
      Personality41 + 
        Personality42 +
        Personality43 +
        Personality44 +
        Personality45 +
        invertItem(Personality46, 1, 5) +
        invertItem(Personality47, 1, 5) +
        invertItem(Personality48, 1, 5) +
        invertItem(Personality49, 1, 5) +
        invertItem(Personality50, 1, 5)))
     
```

## Homeostatically Protected Mood (Core Affect)
Please indicate how each of the following describes your feelings when you think about your life in general. How â€¦.
1.	Happy do you generally feel?
2.	Content do you generally feel?
3.	Alert do you generally feel?

Notes:
Each item is scored on an end-defined rating scale with 0 = not at all, and 10 = extremely.
Items are averaged to provide a single value reflecting homeostatically protected mood (HPMood).


```{r HPMood}
well_being_df <- well_being_df %>% 
  mutate(HPMood = 
           (Affect1 + # Happy
              Affect2 + # Content
              Affect3)/3) # Alert

```


## Multiple Discrepancies Theory (MDT) - Cognition 
Firstly I mutate to a new column labelled "MDT" and averaged.  

1. self_wants 
2. self_other 
3. self_deserves
4. self_needs 
5. self_progress
6. self_future
7. self_past  

Items are averaged to indicate gap between desired and actual life circumstances, such that scores closer to 0 indicate actual circumstances less than desired, scores around 5 reflect life circumstances on par with desired level, and scores closer to 10 indicate actual circumstances are much better than desired.

```{r MDT}
# This will create a new variable with the overal MDT cognition mean score
well_being_df <- well_being_df %>%  
  mutate(MDT =  (
    Cognition1 +
      Cognition2 +
      Cognition3 +
      Cognition4 +
      Cognition5 +
      Cognition6 +
      Cognition7)/7
  )

```

### Model 1
```{r Regression_Part_1}

model1 <- lm(PW_Index ~ 
             HPMood
             , data = well_being_df)

model2 <- lm(PW_Index ~ 
              HPMood
             + MDT 
             , data = well_being_df)

model3 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)


apa.reg.table(model1, model2, model3)

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3)

modelAssumptions(model3) #use the lmsupport library 


```



## Results Table of the first model for comparison
```{r, results="asis"}
#, results="asis"
apa_lm <- apa_print(model3) #apa_print function takes the lm object and creates format strings to report the results
apa_table(apa_lm$table
          , caption = "Regression"
          ) # creates the apa formated table to print to screen

apa_anova <- apa_print(anova(model3))
apa_table(apa_anova$table
          , caption = "ANOVA"
          , note = "Dependant variable: Personal Wellbeing Index")

#N^2 or GES = generalised eta squared

```



### Normality and Residuals

```{r Residuals}

my_residuals <- residuals(model3)
# shapiro-wilk test: compares scores in sample to to norm dist. if the test 
# test is non-sig p>.05 tells us the the dist of sample is not sig different from normal
# If test is sig p<.05 then the distribution in question is significant different from normal. 
# Warning: large sample sizes may get different results. Always plot!
shapiro.test( x = my_residuals )
 
# which finds no indication that normality is violated 
residualPlots(model3)

model3_cooksd <- cooks.distance(model3)

plot(model3_cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance") %>%  # plot cook's distance
  abline(h = 4*mean(model3_cooksd, na.rm=T), col="red") %>%  # add cutoff line - scores 4 times greater than mean
  text(x=1:length(model3_cooksd)+1
       , y=model3_cooksd
       , labels=ifelse(model3_cooksd>4*mean(model3_cooksd, na.rm=T)
                       ,names(model3_cooksd),"")
       , col="red")  # add labels

# find out which rows are influencial
influential <- as.numeric(names(model3_cooksd)[(model3_cooksd > 4*mean(model3_cooksd, na.rm=T))])  # influential row numbers
# head(well_being_df[influential, ])  # influential observations.

outlierTest(model3) #get the most extreme outlier and return row number

# Print which rows are most influencial
influential

# Remove rows
#well_being_df <- well_being_df[-c(2, 19, 21, 84), ]
well_being_df <- well_being_df[-c(2, 21, 27, 30, 78, 84, 86, 88, 101, 104), ]
qqPlot(as.numeric(well_being_df$PW_Index))
modelAssumptions(model3)
```



### Visualise and Check data 


```{r PWI_Plots}

# DV Personal wellbeing index
boxplot(as.numeric(well_being_df$PW_Index)
        , horizontal = TRUE
     , main = "Personal Wellbeing Index"
     , outline = TRUE
     , outwez = TRUE) 
hist(well_being_df$PW_Index)
plot(well_being_df$PW_Index)
```

```{r IV_Plots}

 #HPMood - Affect
boxplot(as.numeric(well_being_df$HPMood)
        , main = "HPMood"
        , horizontal = TRUE
        , outline = TRUE)

plot(well_being_df$HPMood)

#MDT - Cognition
boxplot(as.numeric(well_being_df$MDT) 
        , main = "MDT"
        , horizontal = TRUE)

plot(well_being_df$MDT)


# Create an object with the required columns
boxplot_big5 <- cbind(well_being_df$Neuroticism,
                      well_being_df$Extraversion, 
                      well_being_df$Openness, 
                      well_being_df$Agreeableness, 
                      well_being_df$Conscientiousness) 

#in order to name the boxplot more clearly, create an object with the names
boxplot_names_big5 <- c("N", "E", "O", "A", "C")

# Create a boxplot and use the object boxplot_names_big5 to label each one
boxplot(boxplot_big5, main = "Big 5 Means", names = boxplot_names_big5, horizontal = FALSE) 

```

### Intercorrelations
Check alpha levels (omega) for intercorrelations on each domain. Using the MBES package

#### Personal wellbeing index
The combined survey mean scores from 28 surveys of the Australian population have produced a
maximum variation of 3.2 percentage points in subjective wellbeing (see Australian Unity Wellbeing
Index Report 28.0). Cronbach alpha lies between .70 and .85 in Australia and overseas. Inter-domain
correlations are often moderate at round .30 to .55 and item-total correlations are at least .50. The
index has also demonstrated good test-retest reliability across 1-2 week interval with an intra-class
correlation coefficient of 0.84 (Lau and Cummins, 2005).    


```{r Reliability}

well_being_df <- well_being_df %>% #create an object with personality constructs and reversed scored items
  mutate(Personality6_R =  invertItem(Personality6, 1, 5),
         Personality7_R =  invertItem(Personality7, 1, 5),
         Personality8_R =  invertItem(Personality8, 1, 5),
         Personality9_R =  invertItem(Personality9, 1, 5),
         Personality10_R = invertItem(Personality10, 1, 5),
         Personality16_R = invertItem(Personality16, 1, 5),
         Personality17_R = invertItem(Personality17, 1, 5),
         Personality18_R = invertItem(Personality18, 1, 5),
         Personality19_R = invertItem(Personality19, 1, 5),
         Personality20_R = invertItem(Personality20, 1, 5),
         Personality26_R = invertItem(Personality26, 1,5),
         Personality27_R = invertItem(Personality27, 1,5),
         Personality28_R = invertItem(Personality28, 1,5),
         Personality29_R = invertItem(Personality29, 1,5),
         Personality30_R = invertItem(Personality30, 1,5),
         Personality36_R = invertItem(Personality36, 1, 5),
         Personality37_R = invertItem(Personality37, 1, 5),
         Personality38_R = invertItem(Personality38, 1, 5),
         Personality39_R = invertItem(Personality39, 1, 5),
         Personality40_R = invertItem(Personality40, 1, 5),
         Personality46_R = invertItem(Personality46, 1, 5),
         Personality47_R = invertItem(Personality47, 1, 5),
         Personality48_R = invertItem(Personality48, 1, 5),
         Personality49_R = invertItem(Personality49, 1, 5),
         Personality50_R = invertItem(Personality50, 1, 5))

neo_reliability <- select(well_being_df
         , Personality1
         , Personality2
         , Personality3
         , Personality4
         , Personality5
         , Personality6_R
         , Personality7_R
         , Personality8_R
         , Personality9_R
         , Personality10_R)

ext_reliability <- select(well_being_df
         , Personality11
         , Personality12
         , Personality13
         , Personality14
         , Personality15
         , Personality16_R
         , Personality17_R
         , Personality18_R
         , Personality19_R
         , Personality20_R)


opn_reliability <- select(well_being_df
         , Personality21
         , Personality22
         , Personality23
         , Personality24
         , Personality25
         , Personality26_R
         , Personality27_R
         , Personality28_R
         , Personality29_R
         , Personality30_R)

agre_reliability <- select(well_being_df
         , Personality31
         , Personality32
         , Personality33
         , Personality34
         , Personality35
         , Personality36_R
         , Personality37_R
         , Personality38_R
         , Personality39_R
         , Personality40_R)

conc_reliability <- select(well_being_df
                     , Personality41
                     , Personality42
                     , Personality43
                     , Personality44
                     , Personality45
                     , Personality46_R
                     , Personality47_R
                     , Personality48_R
                     , Personality49_R
                     , Personality50_R)
#run intercorrelation checks
#corPlot(neo_omega)
omega(neo_reliability)

#corPlot(ext_omega)
omega(ext_reliability)

#corPlot(opn_omega)
omega(opn_reliability)

#corPlot(agre_omega)
omega(agre_reliability)

#corPlot(conc_omega)
omega(conc_reliability)

HPmood_alpha <- ci.reliability(select(well_being_df, Affect1, Affect2, Affect3))

MDT_alpha <- ci.reliability(select(well_being_df
             , Cognition1
             , Cognition2
             , Cognition3
             , Cognition4
             , Cognition5
             , Cognition6
             , Cognition7))

pwi_alpha <- ci.reliability(select(well_being_df
             , PWI1
             , PWI2
             , PWI3
             , PWI4
             , PWI5
             , PWI6
             , PWI7))



```

### Testing inline statistics reporting:
The reliability of HPMood was (`r HPmood_alpha$est`) with a CI of \\[ `r HPmood_alpha$ci.lower` `r HPmood_alpha$ci.upper`.


### Regression
Run the model hierarchially and then check assumptions

#### Modelling 

#Good Fit Model
### Re run models
With outliers removed that were leveraging the model, re-run the model. 
```{r Final-model}


model1 <- lm(PW_Index ~ 
             HPMood
             , data = well_being_df)

model2 <- lm(PW_Index ~ 
              HPMood
             + MDT 
             , data = well_being_df)

model3 <- lm(PW_Index ~  
              HPMood 
             + MDT 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)


apa.reg.table(model1, model2, model3)

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3)
```

```{r Cooks}
#Cooks distance check 
model_residuals_3 <- residuals(model3)
shapiro_model <- shapiro.test( x = model_residuals_3 )

model3_residuals_H1 <- cooks.distance(model3)

plot(model3_residuals_H1, pch="*", cex=2, main="Influential Obs by Cooks distance") %>%  # plot cook's distance
  abline(h = 4*mean(model3_residuals_H1, na.rm=T), col="red") %>% # add cutoff line - scores 4 times greater than mean
  text(x=1:length(model3_residuals_H1)+1
       , y=model3_residuals_H1
       , labels=ifelse(model3_residuals_H1>4*mean(model3_residuals_H1, na.rm=T)
                       ,names(model3_residuals_H1),"")
       , col="red")  # add labels

Bonferonni_model <- outlierTest(model3) #get the most extreme outlier and return row number

residualPlots(model3)
Bonferonni_model
```

### With outliers removed re-run the correlations and descriptives
## Descriptives

```{r Descriptives}

Descriptives <- describe(well_being_df[c(1,2,71:78)], fast = TRUE) #descriptives

Descriptives #print descriptive statistics

```


```{r CorrelationTable, results="asis" }

glrstab <- function(x, export=FALSE) {
  
  r <-corr.test(x)$r	#taking just the correlation matrix; no N, or p
  p <-corr.test(x)$p	#taking the p*s
  
  #define notions for significance levels
  mystars <- ifelse(p < .001, "***"
                    , ifelse(p < .01, "**"
                             , ifelse(p < .05, "*"
                                      , ifelse(p < .10, "+", " "))))
  
  #round r, define new matrix Rnew with the correlations from rnd and paste mystars
  rnd  <- papaja::printnum(r, gt1 = FALSE, digits = 2)  #round, drop leading 0 - Thanks CRSH!								                     
  Rnew <- matrix(paste(rnd, mystars, sep=""), ncol=ncol(rnd)) 
  
  #remove 1.0 correlations from diagonal  and set the strings
  diag(Rnew) <- ''		
  Rnew[upper.tri(Rnew)] <- ''								                	
  
  rownames(Rnew) <- paste(1:ncol(rnd), colnames(rnd), sep=" ")         #define number and name
  colnames(Rnew) <- paste(1:ncol(rnd), "", sep="") 			       #define number
  
  #fun-part: we trim the top half 
  Rnew[upper.tri(Rnew)] <- ''			
  Rnew
  
  Rnew <- cbind(round(describe(x)[,3:4],2), Rnew)		     #describe x, M sD - put them in the matrix
  colnames(Rnew)[1:2] <- c("M","SD")					      		#Beschriftung der neuen Spalten
  Rnew <- Rnew[,1:(ncol(Rnew)-1)]							        	#delete the last column (ugly)
  
  #export to clipboard
  
  if (export==TRUE){
    result<-write.table(Rnew
                        , "clipboard"
                        , sep=";"
                        , row.names=FALSE)
  }
  else result <- Rnew
  return(result)
  
}

corr_Matrix <- well_being_df[c(71:78)] #subset relevant columns
a <- glrstab(corr_Matrix) #the function in action!

rownames(a) <- c(
  "PW_Index"
  , "Neuroticism"
  , "Extraversion"
  , "Openness"
  , "Agreeableness"
  , "Conscientiousness"
  , "HPMood"
  , "MDT"
)

colnames(a)   <- c("$M$", "$SD$", "1", "2", "3", "4", "5", "6", "7")

apa_table(a
          , escape  = FALSE
          , format = "html"
          , caption = "Correlation matrix of the main variables"
          , note    = "p<.001***, p<.01**, p<.05*, p<.10+")

```

Correlations between Neuroticism and HPMood, MDT and PWI were all moderatly negative. This pattern can be shared with in that even directionality of constructs on PWI except for extraversion on mood. The positve correlation highlighted that being extraverted and feeling content, happy and alert taps into a more motivated construct and less domain related wellbeing. 




## Tables

```{r Papaja Table, results="asis"}


#step 1
apa_lm_1 <- apa_print(model1) #apa_print function takes the lm object and creates format strings to report the results

apa_table(apa_lm_1$table
          , caption = "Regression Model 1"
          ) # creates the apa formated table to print to screen

apa_anova1 <- apa_print(anova(model1))

apa_table(apa_anova1$table
          , caption = "ANOVA Model 1"
          , note = "Dependant variable: Personal Wellbeing Index")

#step 2
apa_lm_2 <- apa_print(model2) #apa_print function takes the lm object and creates format strings to report the results

apa_table(apa_lm_2$table
          , caption = "Regression Model 2"
          ) # creates the apa formated table to print to screen

apa_anova2 <- apa_print(anova(model2))
apa_table(apa_anova2$table
          , caption = "ANOVA Model 2"
          , note = "Dependant variable: Personal Wellbeing Index")

#step 3
apa_lm_3 <- apa_print(model3) #apa_print function takes the lm object and creates format strings to report the results

apa_table(apa_lm_3$table
          , caption = "Regression Model 3"
          ) # creates the apa formated table to print to screen

apa_anova3 <- apa_print(anova(model3))
apa_table(apa_anova3$table
          , caption = "ANOVA Model3"
          , note = "Dependant variable: Personal Wellbeing Index")



#does this look better?
apa_anova3$table

apa_anova3$full_result$HPMood

```

```{r Partials}
#ols_plot_cooksd_chart(model4)
model1_tolerance_vif <- ols_coll_diag(model1) #Tolerance and vif values

model2_tolerance_vif <- ols_coll_diag(model2)

model3_tolerance_vif <- ols_coll_diag(model3)

#model4_tolerance_vif <- ols_coll_diag(model4)

#model1_partials <- ols_correlations(model1) #part and partials

model2_partials <- ols_correlations(model2)

model3_partials <- ols_correlations(model3)

#model4_partials <- ols_correlations(model4)
```

```{r tolerance_partials}
#model1_tolerance_vif$vif_t
#model1_partials

model2_tolerance_vif$vif_t
model2_partials

model3_tolerance_vif$vif_t
model3_partials

#model4_tolerance_vif$vif_t
#model4_partials

```


### Questions to answer:
#### 1. How much variance do the Ivs account for, together in the DV:R^2
#### 2. What is the relative importance for each of the Ivs in the model: Beta weights
#### 3. Which IV contributes the most unique variance to prediction of the DV: Check sr^2
#### 4. How much improvement in the model occurs when we add an additional IV or group of Ivs: Check R^2 Change

```{r, results='asis'}

#apa.cor.table(corr_Matrix, filename = "correlation_output.doc")

#apa.aov.table(model1, filename = "anova_model1.doc")
#apa.aov.table(model2, filename = "anova_model2.doc")
#apa.aov.table(model3, filename = "anova_model3.doc")

model_final <- apa.reg.table(model1, model2, model3)

```

Notes:
adding any of the personality traits adds little to the variance in the SWB model. This suggests a couple of 
things. The N and E are already accounted for in the afective-cognitive model meaning that a persons set-point is already accounted for by asking contrasting past and future cognitions and their core affect. Secondly, personality traits play little in a persons overall SWB as each traits will modulate their set point differently. The correlation matrix shows N and E are negative and positively correlated respectively. This is important as persons setpoint might be lower if they are feeling depressed or neurotic and in contrast, an extraverted person will more likekly correlate higher with the PWI setpoint when they are feeling in a more positive disposition. 


testing output from data `r apa_lm_1$full_result$modelfit$r2` and seeing if it will print the statistics in with the text.
Use Andy Field's apaTable to print a table directly to seperate word document
```{r}
#write df to file
#write_sav(well_being_df, path  = "data/Wellbeing_2018_df.sav")

```

```{r, results='asis'}
apa_print(list(model1, model2, model3))
```

