---
title: "Lab Report Ver2"
author: "Aaron Willcox"
date: "03/08/2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Included Library, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Included librarys for functions
library(psych)
library(haven)
library(dplyr)
library(lmSupport)
library(papaja)
library(broom)
library(car)
library(olsrr)
library(apaTables)
```

**DV:** Personal Wellbeing Index (pwi)  
**IVs:** Affect(affect HPMood), Cogniton(cognition, MDT), Gender(gender), Personality(personality)
***

```{r Import}
well_being_df <- read_sav("data/Wellbeing_2018.sav")

```

```{r Check Data}
nrows <- nrow(well_being_df)
ncomplete <- sum(complete.cases(well_being_df))
ncomplete/nrows

# Check for missing or na data
which(is.na(well_being_df))
```


All items for the Personal Wellbeing Index (PWI) are measured along a scale ranging from 0 (No satisfaction at all) to 10 (Completely satisfied)
*Total scores on the PWI are obtained by obtaining the average score across the 7 items and then multiplying by 10 to stretch the scale to 0 to 100. 
*As per the PWI manual (http://www.acqol.com.au/uploads/pwi-a/pwi-a-english.pdf ), anyone who scores 0 or 100 is considered unreliable and their data are excluded from analyses involving the PWI (including descriptive statistics such as mean score on the PWI). 
 
Then mutate this to a new column called "PW_Index"
```{r PWI Score}
well_being_df <- well_being_df %>% 
  mutate(PW_Index = (
    PWI1 + 
      PWI2 + 
      PWI3 + 
      PWI4 + 
      PWI5 + 
      PWI6 + 
      PWI7)/7*10)

# Check for scores of zero or 100
PWI_score_check <- filter(well_being_df, well_being_df$PW_Index == 100)

# score of 100 identified at row 1
well_being_df[1,]

# remove the row
well_being_df <- well_being_df[-1,]



```


Notes:
Items are scored on a scale with options 1 = strongly disagree, 2 = disagree, 3 = neither agree nor disagree, 4 = agree, and 5 = strongly agree.
Items 1-10 assess neuroticism. Items 6-10 need to be reverse coded so that high scores across all ten items reflect high levels of neuroticism.

Items 11-20 assess extraversion. Items 16-20 need to be reverse coded so that high scores across all ten items reflect high levels of extraversion.

Items 21-30 assess openness to experience. Items 26-30 need to be reverse coded so that high scores across all ten items reflect high levels of openness.

Items 31-40 assess agreeableness. Items 36-40 need to be reverse coded so that high scores across all ten items reflect high levels of agreeableness.

Items 41-50 assess conscientiousness. Items 46-50 need to be reverse coded so that high scores across all ten items reflect high levels of conscientiousness.

Create the total scores for the subscales by averaging items.
 
These are summed and mutated to a new column for each peronality trait.

```{r Personality}

#Reverse score items 
# M. Ling invert function
invertItem <- function(x, min, max) {
  if(!is.numeric(x) | !is.numeric(min) | !is.numeric(max)) stop("Inputs are not numeric")
  ifelse(max<min, stop("Maximum value is less than minimum value"), "")
  ifelse(x>max | x < min, stop("Value is out of expected range"), "")
  
  reb <- (min-1)
  (max - reb + 1) - (x - reb) + reb
}



# Personality Traits
well_being_df <- well_being_df %>% 
  mutate(Neuroticism = ( # Neuroticism
    Personality1 + 
      Personality2 +
      Personality3 +
      Personality4 +
      Personality5 +
      invertItem(Personality6, 1, 5) +
      invertItem(Personality7, 1, 5) +
      invertItem(Personality8, 1, 5) +
      invertItem(Personality9, 1, 5) +
      invertItem(Personality10, 1, 5)), 
    Extraversion = ( # extraversion
      Personality11 + 
        Personality12 +
        Personality13 +
        Personality14 +
        Personality15 +
        invertItem(Personality16, 1, 5) +
        invertItem(Personality17, 1, 5) +
        invertItem(Personality18, 1, 5) +
        invertItem(Personality19, 1, 5) +
        invertItem(Personality20, 1, 5)),
    Openness = ( # openness
      Personality21 + 
        Personality22 +
        Personality23 +
        Personality24 +
        Personality25 +
        invertItem(Personality26,1,5) +
        invertItem(Personality27,1,5) +
        invertItem(Personality28,1,5) +
        invertItem(Personality29,1,5) +
        invertItem(Personality30,1,5)),
    Agreeableness = ( # Agreeableness
      Personality31 + 
        Personality32 +
        Personality33 +
        Personality34 +
        Personality35 +
        invertItem(Personality36, 1, 5) +
        invertItem(Personality37, 1, 5) +
        invertItem(Personality38, 1, 5) +
        invertItem(Personality39, 1, 5) +
        invertItem(Personality40, 1, 5)),
    Conscientiousness  = (  # conscientiousness
      Personality41 + 
        Personality42 +
        Personality43 +
        Personality44 +
        Personality45 +
        invertItem(Personality46, 1, 5) +
        invertItem(Personality47, 1, 5) +
        invertItem(Personality48, 1, 5) +
        invertItem(Personality49, 1, 5) +
        invertItem(Personality50, 1, 5)))
     
```

Homeostatically Protected Mood (Core Affect)
Please indicate how each of the following describes your feelings when you think about your life in general. How â€¦.
1.	Happy do you generally feel?
2.	Content do you generally feel?
3.	Alert do you generally feel?

Notes:
Each item is scored on an end-defined rating scale with 0 = not at all, and 10 = extremely.
Items are averaged to provide a single value reflecting homeostatically protected mood (HPMood).


```{r HPMood}
well_being_df <- well_being_df %>% 
  mutate(HPMood = 
           (Affect1 + # Happy
              Affect2 + # Content
              Affect3)/3) # Alert

```


Multiple Discrepancies Theory (MDT) - Cognition 
Firstly I mutate to a new column labelled "MDT" and averaged.  

1. self_wants 
2. self_other 
3. self_deserves
4. self_needs 
5. self_progress
6. self_future
7. self_past  

Items are averaged to indicate gap between desired and actual life circumstances, such that scores closer to 0 indicate actual circumstances less than desired, scores around 5 reflect life circumstances on par with desired level, and scores closer to 10 indicate actual circumstances are much better than desired.

```{r MDT}
# This will create a new variable with the overal MDT cognition mean score
well_being_df <- well_being_df %>%  
  mutate(MDT =  (
    Cognition1 +
      Cognition2 +
      Cognition3 +
      Cognition4 +
      Cognition5 +
      Cognition6 +
      Cognition7)/7
  )

```

### Visualise and Check data 


```{r Plots}
# Create an object with the required columns
boxplot_big5 <- cbind(well_being_df$Neuroticism,
                      well_being_df$Extraversion, 
                      well_being_df$Openness, 
                      well_being_df$Agreeableness, 
                      well_being_df$Conscientiousness) 

#in order to name the boxplot more clearly, create an object with the names
boxplot_names_big5 <- c("N", "E", "O", "A", "C")

# Create a boxplot and use the object boxplot_names_big5 to label each one
boxplot(boxplot_big5, main = "Big 5 Means", names = boxplot_names_big5, horizontal = FALSE) 

boxplot(as.numeric(well_being_df$MDT) #MDT - Cognition
        , main = "MDT"
        , horizontal = TRUE)

plot(well_being_df$MDT)

boxplot(as.numeric(well_being_df$HPMood) #HPMood - Affect
        , main = "HPMood"
        , horizontal = TRUE
        , outline = TRUE)

plot(well_being_df$HPMood)

# DV Personal wellbeing index
boxplot(as.numeric(well_being_df$PW_Index)
        , horizontal = TRUE
     , main = "Personal Wellbeing Index"
     , outline = TRUE
     , outwez = TRUE) 

# Positively skewed and almost bimodal
hist(well_being_df$PW_Index)
plot(well_being_df$PW_Index)

qqPlot(as.numeric(well_being_df$PW_Index))
```

## Descriptives
```{r Descriptives}
Descriptives <- describe(well_being_df[c(1,2,71:78)], fast = TRUE) #re-run descriptives

Descriptives #print descriptive statistics



```


## Correlations

Combine into an object variables of interest. Using cbind as calling variables with well_being_df$... removes col names for some reason
```{r Correlation Table, results="asis"}
glrstab <- function(x, export=FALSE) {
  
  r <-corr.test(x)$r	#taking just the correlation matrix; no N, or p
  p <-corr.test(x)$p	#taking the p*s
  
  #define notions for significance levels
  mystars <- ifelse(p < .001, "***"
                    , ifelse(p < .01, "**"
                             , ifelse(p < .05, "*"
                                      , ifelse(p < .10, "+", " "))))
  
  #round r, define new matrix Rnew with the correlations from rnd and paste mystars
  rnd  <- papaja::printnum(r, gt1 = FALSE, digits = 2)  #round, drop leading 0 - Thanks CRSH!								                     
  Rnew <- matrix(paste(rnd, mystars, sep=""), ncol=ncol(rnd)) 
  
  #remove 1.0 correlations from diagonal  and set the strings
  diag(Rnew) <- ''		
  Rnew[upper.tri(Rnew)] <- ''								                	
  
  rownames(Rnew) <- paste(1:ncol(rnd), colnames(rnd), sep=" ")         #define number and name
  colnames(Rnew) <- paste(1:ncol(rnd), "", sep="") 			       #define number
  
  #fun-part: we trim the top half 
  Rnew[upper.tri(Rnew)] <- ''			
  Rnew
  
  Rnew <- cbind(round(describe(x)[,3:4],2), Rnew)		     #describe x, M sD - put them in the matrix
  colnames(Rnew)[1:2] <- c("M","SD")					      		#Beschriftung der neuen Spalten
  Rnew <- Rnew[,1:(ncol(Rnew)-1)]							        	#delete the last column (ugly)
  
  #export to clipboard
  
  if (export==TRUE){
    result<-write.table(Rnew
                        , "clipboard"
                        , sep=";"
                        , row.names=FALSE)
  }
  else result <- Rnew
  return(result)
  
}

corr_Matrix <- well_being_df[c(71:78)] #subset relevant columns
a <- glrstab(corr_Matrix) #the function in action!

rownames(a) <- c(
  "PW_Index"
  , "Neuroticism"
  , "Extraversion"
  , "Openness"
  , "Agreeableness"
  , "Conscientiousness"
  , "HPMood"
  , "MDT"
)

colnames(a)   <- c("$M$", "$SD$", "1", "2", "3", "4", "5", "6", "7")

apa_table(a
          , escape  = FALSE
          , format = "html"
          , caption = "Correlation matrix of the main variables"
          , note    = "p<.001***, p<.01**, p<.05*, p<.10+")


```
Correlations between Neuroticism and HPMood, MDT and PWI were all moderatly negative. This pattern can be shared with in that even directionality of constructs on PWI except for extraversion on mood. The positve correlation highlighted that being extraverted and feeling content, happy and alert taps into a more motivated construct and less domain related wellbeing. 

### Intercorrelations
Check alpha levels (omega) for intercorrelations on each domain. 

#### Personal wellbeing index
The combined survey mean scores from 28 surveys of the Australian population have produced a
maximum variation of 3.2 percentage points in subjective wellbeing (see Australian Unity Wellbeing
Index Report 28.0). Cronbach alpha lies between .70 and .85 in Australia and overseas. Inter-domain
correlations are often moderate at round .30 to .55 and item-total correlations are at least .50. The
index has also demonstrated good test-retest reliability across 1-2 week interval with an intra-class
correlation coefficient of 0.84 (Lau and Cummins, 2005).    

#### Personality

```{r Alpha Check, warning=FALSE}

omega(select(well_being_df, PWI1, PWI2, PWI3, PWI4, PWI5, PWI6, PWI7))

personality_group <- well_being_df %>% #create an object with personality constructs and reversed scored items
  select(num_range("Personality", 1:50)) %>% 
  mutate(Personality6_R = invertItem(Personality6, 1, 5),
         Personality7_R = invertItem(Personality7, 1, 5),
         Personality8_R = invertItem(Personality8, 1, 5),
         Personality9_R = invertItem(Personality9, 1, 5),
         Personality10_R = invertItem(Personality10, 1, 5),
         Personality16_R = invertItem(Personality16, 1, 5),
         Personality17_R = invertItem(Personality17, 1, 5),
         Personality18_R = invertItem(Personality18, 1, 5),
         Personality19_R = invertItem(Personality19, 1, 5),
         Personality20_R = invertItem(Personality20, 1, 5),
         Personality26_R = invertItem(Personality26, 1,5),
         Personality27_R = invertItem(Personality27, 1,5),
         Personality28_R = invertItem(Personality28, 1,5),
         Personality29_R = invertItem(Personality29, 1,5),
         Personality30_R = invertItem(Personality30, 1,5),
         Personality36_R = invertItem(Personality36, 1, 5),
         Personality37_R = invertItem(Personality37, 1, 5),
         Personality38_R = invertItem(Personality38, 1, 5),
         Personality39_R = invertItem(Personality39, 1, 5),
         Personality40_R = invertItem(Personality40, 1, 5),
         Personality46_R = invertItem(Personality46, 1, 5),
         Personality47_R = invertItem(Personality47, 1, 5),
         Personality48_R = invertItem(Personality48, 1, 5),
         Personality49_R = invertItem(Personality49, 1, 5),
         Personality50_R = invertItem(Personality50, 1, 5))

neo_omega <- select(personality_group
                    , Personality1
                    , Personality2
                    , Personality3
                    , Personality4
                    , Personality5
                    , Personality6_R
                    , Personality7_R
                    , Personality8_R
                    , Personality9_R
                    , Personality10_R)

ext_omega <- select(personality_group
                    , Personality11
                    , Personality12
                    , Personality13
                    , Personality14
                    , Personality15
                    , Personality16_R
                    , Personality17_R
                    , Personality18_R
                    , Personality19_R
                    , Personality20_R)


opn_omega <- select(personality_group
                    , Personality21
                    , Personality22
                    , Personality23
                    , Personality24
                    , Personality25
                    , Personality26_R
                    , Personality27_R
                    , Personality28_R
                    , Personality29_R
                    , Personality30_R)

agre_omega <- select(personality_group
                    , Personality31
                    , Personality32
                    , Personality33
                    , Personality34
                    , Personality35
                    , Personality36_R
                    , Personality37_R
                    , Personality38_R
                    , Personality39_R
                    , Personality40_R)

conc_omega <- select(personality_group
                     , Personality41
                     , Personality42
                     , Personality43
                     , Personality44
                     , Personality45
                     , Personality46_R
                     , Personality47_R
                     , Personality48_R
                     , Personality49_R
                     , Personality50_R)

corPlot(neo_omega)
omega(neo_omega)

corPlot(ext_omega)
omega(ext_omega)

corPlot(opn_omega)
omega(opn_omega)

corPlot(agre_omega)
omega(agre_omega)

corPlot(conc_omega)
omega(conc_omega)

omega(select(well_being_df, Affect1, Affect2, Affect3))

omega(select(well_being_df
             , Cognition1
             , Cognition2
             , Cognition3
             , Cognition4
             , Cognition5
             , Cognition6
             , Cognition7))

```




### Regression
Step one of the hierarchial regression will use the two strongest correlates followed by the big
5 then MDT. 

## Modelling 

```{r Regression Part 1}

# Gender_labels <- c("Male", "Female") #set labels for gender factor levels

model1 <- lm(PW_Index ~ Age 
             + Gender
             , data = well_being_df) #baseline obtain total SS


model2 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood
             , data = well_being_df)

model3 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df)

#Hierachial regression 
summary(model1) # Model 1: PW_Index_log10 ~ Age + Gender
summary(model2) # Model 2: PW_Index_log10 ~ Age + Gender + MDT + HPMood
summary(model3) # Model 3: PW_Index_log10 ~ Age + Gender + MDT + Persoanlity traits



# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3)
ANOVA_Models

model_one <- model2

# Model 3 sig at p<.001
# effect_sizes_model3 <- modelEffectSizes(model3, Digits = 2) #check effect sizes and partials

modelAssumptions(model2) #use the lmsupport library 
#model_effect_sizes <- modelEffectSizes(model3) # partial eta squared/effect size/magnitude

ols_plot_cooksd_chart(model3)
ols_coll_diag(model2)
ols_correlations(model2)

apa_lm <- apa_print(model2) #apa_print function takes the lm object and creates format strings to report the results
```

## Results Table
```{r, results="asis"}
apa_table(apa_lm$table
          , caption = "Regression"
          ) # creates the apa formated table to print to screen

apa_anova <- apa_print(anova(model3))
apa_table(apa_anova$table
          , caption = "ANOVA"
          , note = "Dependant variable: Personal Wellbeing Index")

#N^2 or GES = generalised eta squared

```


#### Notes



### Residuals

#### Model 3 come through as the best fit so will check the residuals to see if it can be improved

```{r Residuals}


my_residuals <- residuals(model3)

hist( x = my_residuals )           # plot a histogram 

qqnorm( y = my_residuals )         # draw a QQ plot 
 
# shapiro-wilk test: compares scores in sample to to norm dist. if the test 
# test is non-sig p>.05 tells us the the dist of sample is not sig different from normal
# If test is sig p<.05 then the distribution in question is significant different from normal. 
# Warning: large sample sizes may get different results. Always plot!
shapiro.test( x = my_residuals )
 
# which finds no indication that normality is violated 
residualPlots(model3)

model3_cooksd <- cooks.distance(model3)

plot(model3_cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance

abline(h = 4*mean(model3_cooksd, na.rm=T), col="red")  # add cutoff line - scores 4 times greater than mean

text(x=1:length(model3_cooksd)+1
     , y=model3_cooksd
     , labels=ifelse(model3_cooksd>4*mean(model3_cooksd, na.rm=T)
      ,names(model3_cooksd),"")
     , col="red")  # add labels

# find out which rows are influencial
influential <- as.numeric(names(model3_cooksd)[(model3_cooksd > 4*mean(model3_cooksd, na.rm=T))])  # influential row numbers
# head(well_being_df[influential, ])  # influential observations.

outlierTest(model3) #get the most extreme outlier and return row number

# Print which rows are most influencial
influential

# Remove rows
well_being_df <- well_being_df[-c(2, 19, 21, 84), ]

hist(well_being_df$PW_Index)
```

### Re run models
```{r Re-model}

model1 <- lm(PW_Index ~ Age 
             + Gender
             , data = well_being_df) #baseline obtain total SS


model2 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood
             , data = well_being_df)

model3 <- lm(PW_Index ~ Age 
          + Gender 
          + MDT 
          + HPMood 
          + Neuroticism
          + Extraversion
          + Openness
          + Agreeableness
          + Conscientiousness
          , data = well_being_df)

model4 <- lm(PW_Index ~ Age
             + Gender
             + MDT
             + HPMood
             + Neuroticism
             + Extraversion
             , data = well_being_df)

summary(model1)
summary(model2)
summary(model3)
summary(model4)

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3, model4)
ANOVA_Models

model_two <- model2

my_residuals_2 <- residuals(model2)
shapiro.test( x = my_residuals_2 )

model3_cooksd_new <- cooks.distance(model2)

plot(model3_cooksd_new, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance

abline(h = 4*mean(model3_cooksd_new, na.rm=T), col="red")  # add cutoff line - scores 4 times greater than mean

text(x=1:length(model3_cooksd_new)+1
     , y=model3_cooksd_new
     , labels=ifelse(model3_cooksd_new>4*mean(model3_cooksd_new, na.rm=T)
                     ,names(model3_cooksd_new),"")
     , col="red")  # add labels


residualPlots(model2)




```

## With outliers removed re-run the correlations and descriptives

```{r CorrelationTable, results="asis"}
corr_Matrix2 <- well_being_df[c(71:78)] #subset relevant columns
a2 <- glrstab(corr_Matrix2) #the function in action!

rownames(a2) <- c(
  "PW_Index"
  , "Neuroticism"
  , "Extraversion"
  , "Openness"
  , "Agreeableness"
  , "Conscientiousness"
  , "HPMood"
  , "MDT"
)

colnames(a2)   <- c("$M$", "$SD$", "1", "2", "3", "4", "5", "6", "7")

apa_table(a2
          , escape  = FALSE
          , format = "html"
          , caption = "Correlation matrix of the main variables"
          , note    = "p<.001***, p<.01**, p<.05*, p<.10+")
```

```{r Means}

Descriptives2 <- describe(well_being_df[c(1,2,71:78)], fast = TRUE) #re-run descriptives

Descriptives2 #print descriptive statistics

```


## Tables

```{r Papaja Table , results="asis"}

apa_lm <- apa_print(model2) #apa_print function takes the lm object and creates format strings to report the results

apa_table(apa_lm$table
          , caption = "Regression"
          ) # creates the apa formated table to print to screen

apa_anova <- apa_print(anova(model2))
apa_table(apa_anova$table
          , caption = "ANOVA"
          , note = "Dependant variable: Personal Wellbeing Index")
```

```{r moreplots}

ols_plot_cooksd_chart(model2)
ols_coll_diag(model2)
ols_coll_diag(model3)
ols_coll_diag(model4)
ols_correlations(model2)
ols_correlations(model3)
ols_correlations(model4)

#using glance I can pull specifc data from the object
model_statistics <- glance(model2)



```

### Questions to answer:
#### 1. How much variance do the Ivs account for, together in the DV:R^2
#### 2. What is the relative importance for each of the Ivs in the model: Beta weights
#### 3. Which IV contributes the most unique variance to prediction of the DV: Check sr^2
#### 4. How much improvement in the model occurs when we add an additional IV or group of Ivs: Check R^2 Change

```{r}
# Using the Broom library I can pull the model estimates from an assigned object 
# as needed. 
m1 <- glance(model1)
m2 <- glance(model2)
m3 <- glance(model3)


Descriptives <- tibble::tribble(
  ~model, ~R2, ~adj.R2,
  "Model 1",  round(m1$r.squared, digits = 2),  round(m1$adj.r.squared, digits = 2),
  "Model 2",  round(m2$r.squared, digits = 2), round(m2$adj.r.squared, digits = 2),
  "Model 3",   round(m3$r.squared, digits = 2), round(m3$adj.r.squared, digits = 2)
)

require(rhandsontable)
rhandsontable(Descriptives, rowHeaders = NULL,
               digits = 3, useTypes = FALSE, search = FALSE,
               width = NULL, height = NULL)

```


```{r}

apa.cor.table(corr_Matrix)

apa.aov.table(model3)

```

Notes:
adding any of the personality traits adds little to the variance in the SWB model. This suggests a couple of 
things. The N and E are already accounted for in the afective-cognitive model meaning that a persons set-point is already accounted for by asking contrasting past and future cognitions and their core affect. Secondly, personality traits play little in a persons overall SWB as each traits will modulate their set point differently. The correlation matrix shows N and E are negative and positively correlated respectively. This is important as persons setpoint might be lower if they are feeling depressed or neurotic and in contrast, an extraverted person will more likekly correlate higher with the PWI setpoint when they are feeling in a more positive disposition. 

