---
title: "Lab Report Ver2"
author: "Aaron Willcox"
date: "03/08/2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Included Library, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Included librarys for functions
library(psych)
library(haven)
library(dplyr)
library(lmSupport)
library(papaja)
library(broom)
library(car)
```

**DV:** Personal Wellbeing Index (pwi)  
**IVs:** Affect(affect HPMood), Cogniton(cognition, MDT), Gender(gender), Personality(personality)
***

```{r Import}
well_being_df <- read_sav("data/Wellbeing_2018.sav")

```

```{r Check Data}
nrows <- nrow(well_being_df)
ncomplete <- sum(complete.cases(well_being_df))
ncomplete/nrows

# Check for missing or na data
which(is.na(well_being_df))
```


All items for the Personal Wellbeing Index (PWI) are measured along a scale ranging from 0 (No satisfaction at all) to 10 (Completely satisfied)
*Total scores on the PWI are obtained by obtaining the average score across the 7 items and then multiplying by 10 to stretch the scale to 0 to 100. 
*As per the PWI manual (http://www.acqol.com.au/uploads/pwi-a/pwi-a-english.pdf ), anyone who scores 0 or 100 is considered unreliable and their data are excluded from analyses involving the PWI (including descriptive statistics such as mean score on the PWI). 
 
Then mutate this to a new column called "PW_Index"
```{r PWI Score}
well_being_df <- well_being_df %>% 
  mutate(PW_Index = (
    PWI1 + 
      PWI2 + 
      PWI3 + 
      PWI4 + 
      PWI5 + 
      PWI6 + 
      PWI7)/7*10)

# Check for scores of zero or 100
PWI_score_check <- filter(well_being_df, well_being_df$PW_Index == 100)

# score of 100 identified at row 1
well_being_df[1,]

# remove the row
well_being_df <- well_being_df[-1,]



```


Notes:
Items are scored on a scale with options 1 = strongly disagree, 2 = disagree, 3 = neither agree nor disagree, 4 = agree, and 5 = strongly agree.
Items 1-10 assess neuroticism. Items 6-10 need to be reverse coded so that high scores across all ten items reflect high levels of neuroticism.

Items 11-20 assess extraversion. Items 16-20 need to be reverse coded so that high scores across all ten items reflect high levels of extraversion.

Items 21-30 assess openness to experience. Items 26-30 need to be reverse coded so that high scores across all ten items reflect high levels of openness.

Items 31-40 assess agreeableness. Items 36-40 need to be reverse coded so that high scores across all ten items reflect high levels of agreeableness.

Items 41-50 assess conscientiousness. Items 46-50 need to be reverse coded so that high scores across all ten items reflect high levels of conscientiousness.

Create the total scores for the subscales by averaging items.
 
These are summed and mutated to a new column for each peronality trait.

```{r Personality}

#Reverse score items 
# M. Ling invert function
invertItem <- function(x, min, max) {
  if(!is.numeric(x) | !is.numeric(min) | !is.numeric(max)) stop("Inputs are not numeric")
  ifelse(max<min, stop("Maximum value is less than minimum value"), "")
  ifelse(x>max | x < min, stop("Value is out of expected range"), "")
  
  reb <- (min-1)
  (max - reb + 1) - (x - reb) + reb
}



# Personality Traits
well_being_df <- well_being_df %>% 
  mutate(Neuroticism = ( # Neuroticism
    Personality1 + 
      Personality2 +
      Personality3 +
      Personality4 +
      Personality5 +
      invertItem(Personality6, 1, 5) +
      invertItem(Personality7, 1, 5) +
      invertItem(Personality8, 1, 5) +
      invertItem(Personality9, 1, 5) +
      invertItem(Personality10, 1, 5)), 
    Extraversion = ( # extraversion
      Personality11 + 
        Personality12 +
        Personality13 +
        Personality14 +
        Personality15 +
        Personality16 +
        Personality17 +
        Personality18 +
        Personality19 +
        Personality20),
    Openness = ( # openness
      Personality21 + 
        Personality22 +
        Personality23 +
        Personality24 +
        Personality25 +
        invertItem(Personality26,1,5) +
        invertItem(Personality27,1,5) +
        invertItem(Personality28,1,5) +
        invertItem(Personality29,1,5) +
        invertItem(Personality30,1,5)),
    Agreeableness = ( # Agreeableness
      Personality31 + 
        Personality32 +
        Personality33 +
        Personality34 +
        Personality35 +
        invertItem(Personality36, 1, 5) +
        invertItem(Personality37, 1, 5) +
        invertItem(Personality38, 1, 5) +
        invertItem(Personality39, 1, 5) +
        invertItem(Personality40, 1, 5)),
    Conscientiousness  = (  # conscientiousness
      Personality41 + 
        Personality42 +
        Personality43 +
        Personality44 +
        Personality45 +
        invertItem(Personality46, 1, 5) +
        invertItem(Personality47, 1, 5) +
        invertItem(Personality48, 1, 5) +
        invertItem(Personality49, 1, 5) +
        invertItem(Personality50, 1, 5)))

well_being_df <- well_being_df %>%  #personality group
  mutate(Personality = 
           (Personality1 +
           Personality2 +
           Personality3 + 
           Personality4 +
           Personality5 +
           Personality6 +
           Personality7 +
           Personality8 +
           Personality9 +
           Personality10 +
           Personality11 + 
           Personality12 +
           Personality13 +
           Personality14 +
           Personality15 +
           Personality16 +
           Personality17 +
           Personality18 +
           Personality19 +
           Personality20 +
           Personality21 + 
           Personality22 +
           Personality23 +
           Personality24 +
           Personality25 +
           Personality26 +
           Personality27 +
           Personality28 +
           Personality29 +
           Personality30 +
           Personality31 + 
           Personality32 +
           Personality33 +
           Personality34 +
           Personality35 +
           Personality36 +
           Personality37 +
           Personality38 +
           Personality39 +
           Personality40 +
           Personality41 + 
           Personality42 +
           Personality43 +
           Personality44 +
           Personality45 +
           Personality46 +
           Personality47 +
           Personality48 +
           Personality49 +
           Personality50)/50*10)
     
```

Homeostatically Protected Mood (Core Affect)
Please indicate how each of the following describes your feelings when you think about your life in general. How â€¦.
1.	Happy do you generally feel?
2.	Content do you generally feel?
3.	Alert do you generally feel?

Notes:
Each item is scored on an end-defined rating scale with 0 = not at all, and 10 = extremely.
Items are averaged to provide a single value reflecting homeostatically protected mood (HPMood).


```{r HPMood}
well_being_df <- well_being_df %>% 
  mutate(HPMood = 
           (Affect1 + # Happy
              Affect2 + # Content
              Affect3)/3) # Alert

```


Multiple Discrepancies Theory (MDT) - Cognition 
Firstly I mutate to a new column labelled "MDT" and averaged.  

1. self_wants 
2. self_other 
3. self_deserves
4. self_needs 
5. self_progress
6. self_future
7. self_past  

Items are averaged to indicate gap between desired and actual life circumstances, such that scores closer to 0 indicate actual circumstances less than desired, scores around 5 reflect life circumstances on par with desired level, and scores closer to 10 indicate actual circumstances are much better than desired.

```{r MDT}
# This will create a new variable with the overal MDT cognition mean score
well_being_df <- well_being_df %>%  
  mutate(MDT =  (
    Cognition1 +
      Cognition2 +
      Cognition3 +
      Cognition4 +
      Cognition5 +
      Cognition6 +
      Cognition7)/7
  )

```

### Check data 

If looking for relationships between variables then transform the problematic variable if looking for differences then transform all needed variables. 

```{r Plots}
boxplot(as.numeric(well_being_df$Neuroticism)
        , main = "Neuroticism"
        , horizontal = TRUE)

boxplot(as.numeric(well_being_df$Extraversion)
        , main = "Extraversion"
        , horizontal = TRUE) 

boxplot(as.numeric(well_being_df$Openness)
        , main = "Openness"
        , horizontal = TRUE)

boxplot(as.numeric(well_being_df$Agreeableness)
        , main = "Agreeableness"
        , horizontal = TRUE)

boxplot(as.numeric(well_being_df$Conscientiousness)
        , main = "Conscientiousness"
        , horizontal = TRUE)

# Create an object with the requrired columns
boxplot_big5 <- cbind(well_being_df$Neuroticism,
                      well_being_df$Extraversion, 
                      well_being_df$Openness, 
                      well_being_df$Agreeableness, 
                      well_being_df$Conscientiousness) 

#in order to name the boxplot more clearly, create an object with the names
boxplot_names_big5 <- c("N", "E", "O", "A", "C")

# Create a boxplot and use the object boxplot_names_big5 to label each one
boxplot(boxplot_big5, main = "Big 5 Means", names = boxplot_names_big5, horizontal = FALSE) 

boxplot(as.numeric(well_being_df$MDT)
        , main = "MDT"
        , horizontal = TRUE)

boxplot(as.numeric(well_being_df$Personality)
        , main = "Personality"
        , horizontal = TRUE) 

boxplot(as.numeric(well_being_df$HPMood)
        , main = "HPMood"
        , horizontal = TRUE
        , outline = TRUE)

# A few outliers in the DV
boxplot(as.numeric(well_being_df$PW_Index)
        , horizontal = TRUE
     , main = "Personal Wellbeing Index"
     , outline = TRUE
     , outwez = TRUE) 

# Positively skewed and almost bimodal
hist(well_being_df$PW_Index)

plot(well_being_df$PW_Index)

# qqPlot(well_being_df$PW_Index)

boxplot.stats(well_being_df$PW_Index)

Descriptives <- describe(well_being_df[c(1,2,71:79)], fast = TRUE) #re-run descriptives

Descriptives #print descriptive statistics

boxplot(as.numeric(well_being_df$HPMood), horizontal = TRUE)
# Still seeing some smapling bias in scores and distribution is positively skewed
# This could violates our assumption of normality
# run a boxplot



# Extraversion has some outliers

```


## Correlations

Combine into an object variables of interest. Using cbind as calling variables with well_being_df$... removes col names for some reason
```{r Correlation Table, results="asis"}
glrstab <- function(x, export=FALSE) {
  
  r <-corr.test(x)$r	#taking just the correlation matrix; no N, or p
  p <-corr.test(x)$p	#taking the p*s
  
  #define notions for significance levels
  mystars <- ifelse(p < .001, "***"
                    , ifelse(p < .01, "**"
                             , ifelse(p < .05, "*"
                                      , ifelse(p < .10, "+", " "))))
  
  #round r, define new matrix Rnew with the correlations from rnd and paste mystars
  rnd  <- papaja::printnum(r, gt1 = FALSE, digits = 2)  #round, drop leading 0 - Thanks CRSH!								                     
  Rnew <- matrix(paste(rnd, mystars, sep=""), ncol=ncol(rnd)) 
  
  #remove 1.0 correlations from diagonal  and set the strings
  diag(Rnew) <- ''		
  Rnew[upper.tri(Rnew)] <- ''								                	
  
  rownames(Rnew) <- paste(1:ncol(rnd), colnames(rnd), sep=" ")         #define number and name
  colnames(Rnew) <- paste(1:ncol(rnd), "", sep="") 			       #define number
  
  #fun-part: we trim the top half 
  Rnew[upper.tri(Rnew)] <- ''			
  Rnew
  
  Rnew <- cbind(round(describe(x)[,3:4],2), Rnew)		     #describe x, M sD - put them in the matrix
  colnames(Rnew)[1:2] <- c("M","SD")					      		#Beschriftung der neuen Spalten
  Rnew <- Rnew[,1:(ncol(Rnew)-1)]							        	#delete the last column (ugly)
  
  #export to clipboard
  
  if (export==TRUE){
    result<-write.table(Rnew
                        , "clipboard"
                        , sep=";"
                        , row.names=FALSE)
  }
  else result <- Rnew
  return(result)
  
}

corr_Matrix <- well_being_df[c(1:2, 71:79)] #subset relevant columns
a <- glrstab(corr_Matrix) #the function in action!

rownames(a) <- c( "Age"
                 , "Gender"
                 , "PW_Index"
                 , "Neuroticism"
                 , "Extraversion"
                 , "Openness"
                 , "Agreeableness"
                 , "Conscientiousness"
                 , "Personality"
                 , "HPMood"
                 , "MDT"
                 )

colnames(a)   <- c("$M$", "$SD$", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10")

apa_table(a
          , escape  = FALSE
          , format = "html"
          , caption = "Correlation matrix of the main variables"
          , note    = "p<.001***, p<.01**, p<.05*, p<.10+")


```
Correlations between Neuroticism and HPMood, MDT and PWI were all moderatly negative. This pattern can be shared with in that even directionality of constructs on PWI except for extraversion on mood. The positve correlation highlighted that being extraverted and feeling content, happy and alert taps into a more motivated construct and less domain related wellbeing. 

### Regression
Step one of the multiple regression will use the two strongest correlates followed by the big
5 then MDT. 

## Modelling 

```{r Regression Part 1}

Gender_labels <- c("Male", "Female") #set labels for gender factor levels

model1 <- lm(PW_Index ~ Age 
             + Gender
             , data = well_being_df) #baseline obtain total SS

model2 <- lm(PW_Index ~ Age 
             + Gender
             + MDT
             , data = well_being_df) #use known sign effects first based on previous research

model3 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood
             , data = well_being_df)

model4 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood 
             + Personality
             , data = well_being_df) #additional of personality groups

model5 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df) #run with personality traits

#Hierachial regression 
summary(model1) # Model 1: PW_Index_log10 ~ Age + Gender
summary(model2) # Model 2: PW_Index_log10 ~ Age + Gender + MDT
summary(model3) # Model 3: PW_Index_log10 ~ Age + Gender + MDT + HPMood
summary(model4) # Model 3: PW_Index_log10 ~ Age + Gender + MDT + HPMood + group personality
summary(model5) # with personality traits

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3, model4, model5)
ANOVA_Models

# Model 3 sig at p<.001
effect_sizes_model3 <- modelEffectSizes(model3, Digits = 2) #check effect sizes and partials

modelAssumptions(model3) #use the lmsupport library 
model_effect_sizes <- modelEffectSizes(model3) # partial eta squared/effect size/magnitude

apa_lm <- apa_print(model3) #apa_print function takes the lm object and creates format strings to report the results
```

## Results Table
```{r, results="asis"}
apa_table(apa_lm$table
          , caption = "Regression"
          ) # creates the apa formated table to print to screen

apa_anova <- apa_print(anova(model3))
apa_table(apa_anova$table
          , caption = "ANOVA"
          , note = "Dependant variable: Personal Wellbeing Index")


```


#### Notes

pETA: MDT in model 2 accounted for .30 of the unique variance on PWI scores however, 
n the next step, the addition of HPMood account for .20 and MDT dropped down to .05.
This trend can be seen in teh beta coefficients as well. Need to treat outliers in the DV


### Residuals

#### Model 3 come through as the best fit so will check the residuals to see if it can be improved

```{r Residuals}


my_residuals <- residuals(model3)

hist( x = my_residuals )           # plot a histogram 

qqnorm( y = my_residuals )         # draw a QQ plot 
 
# shapiro-wilk test: compares scores in sample to to norm dist. if the test 
# test is non-sig p>.05 tells us the the dist of sample is not sig different from normal
# If test is sig p<.05 then the distribution in question is significant different from normal. 
# Warning: large sample sizes may get different results. Always plot!
shapiro.test( x = my_residuals )
 
# which finds no indication that normality is violated 
residualPlots(model3)

model3_cooksd <- cooks.distance(model3)

plot(model3_cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance

abline(h = 4*mean(model3_cooksd, na.rm=T), col="red")  # add cutoff line - scores 4 times greater than mean

text(x=1:length(model3_cooksd)+1
     , y=model3_cooksd
     , labels=ifelse(model3_cooksd>4*mean(model3_cooksd, na.rm=T)
                     ,names(model3_cooksd),"")
     , col="red")  # add labels

# find out which rows are influencial
influential <- as.numeric(names(model3_cooksd)[(model3_cooksd > 4*mean(model3_cooksd, na.rm=T))])  # influential row numbers
# head(well_being_df[influential, ])  # influential observations.

outlierTest(model3) #get the most extreme outlier and return row number

# Print which rows are most influencial
influential

# Remove rows
well_being_df <- well_being_df[-c(2, 19, 21, 66, 81), ]

hist(well_being_df$PW_Index)
```

### Re run models
```{r Re-model}

model1 <- lm(PW_Index ~ Age 
             + Gender
             , data = well_being_df) #baseline obtain total SS

model2 <- lm(PW_Index ~ Age 
             + Gender
             + MDT
             , data = well_being_df) #use known sign effects first based on previous research

model3 <- lm((PW_Index) ~ Age 
             + Gender 
             + MDT 
             + HPMood
             , data = well_being_df)

model4 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood 
             + Personality
             , data = well_being_df) #additional of personality groups

model5 <- lm(PW_Index ~ Age 
             + Gender 
             + MDT 
             + HPMood 
             + Neuroticism
             + Extraversion
             + Openness
             + Agreeableness
             + Conscientiousness
             , data = well_being_df) #run with personality traits

#Hierachial regression 
#summary(model1) # Model 1: PW_Index_log10 ~ Age + Gender
#summary(model2) # Model 2: PW_Index_log10 ~ Age + Gender + MDT
summary(model3) # Model 3: PW_Index_log10 ~ Age + Gender + MDT + HPMood
#summary(model4) # Model 3: PW_Index_log10 ~ Age + Gender + MDT + HPMood + group personality
#summary(model5) # with personality traits

# Run an ANOVA to check for sig effect. 
ANOVA_Models <- anova(model1, model2, model3, model4, model5)
ANOVA_Models

my_residuals_2 <- residuals(model3)
shapiro.test( x = my_residuals_2 )

model3_cooksd_new <- cooks.distance(model3)

plot(model3_cooksd_new, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance

abline(h = 4*mean(model3_cooksd_new, na.rm=T), col="red")  # add cutoff line - scores 4 times greater than mean

text(x=1:length(model3_cooksd_new)+1
     , y=model3_cooksd_new
     , labels=ifelse(model3_cooksd_new>4*mean(model3_cooksd_new, na.rm=T)
                     ,names(model3_cooksd_new),"")
     , col="red")  # add labels


residualPlots(model3)




```

## Tables

```{r Papaja Table , results="asis"}

apa_lm <- apa_print(model3) #apa_print function takes the lm object and creates format strings to report the results

apa_table(apa_lm$table
          , caption = "Regression"
          ) # creates the apa formated table to print to screen

apa_anova <- apa_print(anova(model3))
apa_table(apa_anova$table
          , caption = "ANOVA"
          , note = "Dependant variable: Personal Wellbeing Index")



#using glance I can pull specifc data from the object
model_statistics <- glance(model3)



```

### Questions to answer:
#### 1. How much variance do the Ivs account for, together in the DV:R^2
#### 2. What is the relative importance for each of the Ivs in the model: Beta weights
#### 3. Which IV contributes the most unique variance to prediction of the DV: Check sr^2
#### 4. How much improvement in the model occurs when we add an additional IV or group of Ivs: Check R^2 Change

```{r}
# Using the Broom library I can pull the model estimates from an assigned object 
# as needed. 
m1 <- glance(model1)
m2 <- glance(model2)
m3 <- glance(model3)
m4 <- glance(model4)
m5 <- glance(model5)

Descriptives <- tibble::tribble(
  ~model, ~R2, ~adj.R2,
  "Model 1",  round(m1$r.squared, digits = 2),  round(m1$adj.r.squared, digits = 2),
  "Model 2",  round(m2$r.squared, digits = 2), round(m2$adj.r.squared, digits = 2),
  "Model 3",   round(m3$r.squared, digits = 2), round(m3$adj.r.squared, digits = 2),
  "Model 4",   round(m4$r.squared, digits = 2), round(m4$adj.r.squared, digits = 2),
  "Model 5",   round(m5$r.squared, digits = 2), round(m5$adj.r.squared, digits = 2)
)

require(rhandsontable)
rhandsontable(Descriptives, rowHeaders = NULL,
               digits = 3, useTypes = FALSE, search = FALSE,
               width = NULL, height = NULL)

```

